{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a321bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples are:  777\n",
      "Out of these, training examples are:  543\n",
      "Test examples are:  234\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51226/96569626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;31m# prepare model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanAndStdDevForClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m# test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_51226/96569626.py\u001b[0m in \u001b[0;36mMeanAndStdDevForClass\u001b[0;34m(mydata)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupUnderClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclassValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassValue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_51226/96569626.py\u001b[0m in \u001b[0;36mMeanAndStdDev\u001b[0;34m(mydata)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;31m# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_51226/96569626.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMeanAndStdDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;31m# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_51226/96569626.py\u001b[0m in \u001b[0;36mstd_dev\u001b[0;34m(numbers)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    " \n",
    " \n",
    "# the categorical class names are changed to numberic data\n",
    "# eg: yes and no encoded to 1 and 0\n",
    "def encode_class(mydata):\n",
    "    classes = []\n",
    "    for i in range(len(mydata)):\n",
    "        if mydata[i][-1] not in classes:\n",
    "            classes.append(mydata[i][-1])\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(mydata)):\n",
    "            if mydata[j][-1] == classes[i]:\n",
    "                mydata[j][-1] = i\n",
    "    return mydata           \n",
    "             \n",
    " \n",
    "# Splitting the data\n",
    "def splitting(mydata, ratio):\n",
    "    train_num = int(len(mydata) * ratio)\n",
    "    train = []\n",
    "    # initially testset will have all the dataset\n",
    "    test = list(mydata)\n",
    "    while len(train) < train_num:\n",
    "        # index generated randomly from range 0\n",
    "        # to length of testset\n",
    "        index = random.randrange(len(test))\n",
    "        # from testset, pop data rows and put it in train\n",
    "        train.append(test.pop(index))\n",
    "    return train, test\n",
    " \n",
    " \n",
    "# Group the data rows under each class yes or\n",
    "# no in dictionary eg: dict[yes] and dict[no]\n",
    "def groupUnderClass(mydata):\n",
    "      dict = {}\n",
    "      for i in range(len(mydata)):\n",
    "          if (mydata[i][-1] not in dict):\n",
    "              dict[mydata[i][-1]] = []\n",
    "          dict[mydata[i][-1]].append(mydata[i])\n",
    "      return dict\n",
    " \n",
    " \n",
    "# Calculating Mean\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    " \n",
    "# Calculating Standard Deviation\n",
    "def std_dev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    " \n",
    "def MeanAndStdDev(mydata):\n",
    "    info = [(mean(attribute), std_dev(attribute)) for attribute in zip(*mydata)]\n",
    "    # eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\n",
    "    # here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\n",
    "    # delete summaries of last class\n",
    "    del info[-1]\n",
    "    return info\n",
    " \n",
    "# find Mean and Standard Deviation under each class\n",
    "def MeanAndStdDevForClass(mydata):\n",
    "    info = {}\n",
    "    dict = groupUnderClass(mydata)\n",
    "    for classValue, instances in dict.items():\n",
    "        info[classValue] = MeanAndStdDev(instances)\n",
    "    return info\n",
    " \n",
    " \n",
    "# Calculate Gaussian Probability Density Function\n",
    "def calculateGaussianProbability(x, mean, stdev):\n",
    "    expo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * expo\n",
    " \n",
    " \n",
    "# Calculate Class Probabilities\n",
    "def calculateClassProbabilities(info, test):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in info.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, std_dev = classSummaries[i]\n",
    "            x = test[i]\n",
    "            probabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
    "    return probabilities\n",
    " \n",
    " \n",
    "# Make prediction - highest probability is the prediction\n",
    "def predict(info, test):\n",
    "    probabilities = calculateClassProbabilities(info, test)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    " \n",
    " \n",
    "# returns predictions for a set of examples\n",
    "def getPredictions(info, test):\n",
    "    predictions = []\n",
    "    for i in range(len(test)):\n",
    "        result = predict(info, test[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    " \n",
    "# Accuracy score\n",
    "def accuracy_rate(test, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(test))) * 100.0\n",
    " \n",
    " \n",
    "# driver code\n",
    " \n",
    "# add the data path in your system\n",
    "filename = r'/root/gj/ML/nav.csv'\n",
    " \n",
    " \n",
    "# load the file and store it in mydata list\n",
    "mydata = csv.reader(open(filename, \"rt\"))\n",
    "#mydata=pd.read_csv('nav.csv')\n",
    "mydata = list(mydata)\n",
    "mydata = encode_class(mydata)\n",
    "for i in range(len(mydata)):\n",
    "    mydata[i] = [float(x) for x in mydata[i]]\n",
    " \n",
    "     \n",
    "# split ratio = 0.7\n",
    "# 70% of data is training data and 30% is test data used for testing\n",
    "ratio = 0.7\n",
    "train_data, test_data = splitting(mydata, ratio)\n",
    "print('Total number of examples are: ', len(mydata))\n",
    "print('Out of these, training examples are: ', len(train_data))\n",
    "print(\"Test examples are: \", len(test_data))\n",
    " \n",
    "# prepare model\n",
    "info = MeanAndStdDevForClass(train_data)\n",
    " \n",
    "# test model\n",
    "predictions = getPredictions(info, test_data)\n",
    "accuracy = accuracy_rate(test_data, predictions)\n",
    "print(\"Accuracy of your model is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323a713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa51ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
